# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1
# Use a package of configuration called an orb.

#first smoke test
#URL="https://blog.udacity.com/"
          # Test if website exists
          #if curl -s --head ${URL} 
          #then
           #return 0
          #lse
          # return 1
          #fi
orbs:
  # Choose either one of the orbs below
  # welcome: circleci/welcome-orb@0.4.1
   aws-cli: circleci/aws-cli@2.0.3
# Define the jobs we want to run for this project
commands:
  destroy_environments:
    steps:
       - run:
           name: Destroy environment
           # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
           # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
           when: on_fail
           command: |
             aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:7}

jobs:
  create_infrastructure:  # Choose any name, such as `build`
      # The primary container, where your job's commands will run
      docker:  
      - image: amazon/aws-cli
      steps:
        - checkout # check out the code in the project directory
        - run: 
            name: Create Cloudformation Stack
            command: |
               aws cloudformation deploy \
               --template-file template.yml \
               --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:7} \
               --region us-east-1
        - run: return 1
        - destroy_environments

  add_ipto_inventory:
    docker:  
      - image: amazon/aws-cli
    steps:
    - checkout
    - run:
        aws ec2 describe-instances \
        --query 'Reservations[*].Instances[*].PublicIpAddress' \
        --output text >> inventory.txt

    - persist_to_workspace:
          root: ~/
          paths:
            - inventory.txt


  configure_infrastructure:

    docker:
    - image: python:3.7-alpine3.11
    steps:
    - checkout
    - add_ssh_keys:
            # You can get this ID in the section where you registered the SSH Key
            fingerprints: ["15:04:8a:7b:7f:d7:34:8d:bc:28:53:8d:c3:6b:69:e6"] 
    - run:
        name: Install Ansible
        command: |
           apk add --update ansible 
        # Install Ansible
    - run:
        name: Run Playbook and Configure server
        command: | 
          ansible-playbook -i inventory.txt main4.yml
  smoke_test:
    docker:
     - image: alpine:latest
    steps:
      - run: apk add --update curl
      - run:
         name: smoke test
         command: return 1
      - destroy_environments


  create_and_deploy_front_end:
     docker:
        - image: amazon/aws-cli
     steps:
        - checkout
        - run:
            name: Execute bucket.yml - Create Cloudformation Stack
            command: |
              aws cloudformation deploy \
              --template-file bucket.yml \
              --stack-name stack-create-bucket-bucketpr111 \
              --parameter-overrides MyBucketName="bucketpr111"
           # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
        - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete



  get_last_deployment_id:

     docker:
       - image: amazon/aws-cli
     steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
           aws cloudformation \
           list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
           --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths: 
            - textfile.txt 

  promote_to_production:

     docker:
        - image: amazon/aws-cli
     steps:
       - checkout
       - run:
          name: Execute cloudfront.yml
          command: |
             aws cloudformation deploy \
             --template-file cloudfront.yml \
             --stack-name production-distro \
             --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"

  clean_up_old_front_end:
    docker:
    - image: amazon/aws-cli
    steps:
    - checkout
    - run: yum install -y tar gzip
    - attach_workspace:
        at: ~/
    - run:
        name: Destroy the previous S3 bucket and CloudFormation stack. 
        # Use $OldBucketID environment variable or mybucket644752792305 below.
        # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
        command: |
          export OldBucketID=$(cat ~/textfile.txt)
          aws s3 rm "s3://${OldBucketID}" --recursive

          

# Sequential workflow
workflows:
  # Name the workflow
  myWorkflow:
    jobs:
      #- create_infrastructure
      #- add_ipto_inventory:
             #requires:
              # - create_infrastructure
      #- configure_infrastructure
             #requires:  
                 #- add_ipto_inventory
      #-  smoke_test:
       #   requires:
        #   - create_infrastructure
      - create_and_deploy_front_end
      - promote_to_production:
            requires: 
              - create_and_deploy_front_end
      - get_last_deployment_id
      - clean_up_old_front_end:
            requires:
              - get_last_deployment_id
              - promote_to_production